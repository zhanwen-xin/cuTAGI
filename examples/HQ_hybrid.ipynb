{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary import. It will be removed in the final vserion\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/Users/zhanwenxin/Documents/GitHub/cuTAGI-LSTM')\n",
    "\n",
    "from typing import Union, Optional\n",
    "\n",
    "import fire\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytagi.metric as metric\n",
    "from pytagi import Normalizer as normalizer\n",
    "from pytagi import exponential_scheduler\n",
    "from pytagi.nn import LSTM, Linear, OutputUpdater, Sequential\n",
    "\n",
    "from examples.data_loader import TimeSeriesDataloader\n",
    "from pytagi.hybrid import LSTM_SSM\n",
    "from pytagi.hybrid import process_input_ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LSTM_SSM.__init__() got an unexpected keyword argument 'Sigma_AA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m LA_var_stationary \u001b[38;5;241m=\u001b[39m Sigma_AA\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mphi_AA\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Autoregressive acceleration + online AR\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m hybrid \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM_SSM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneural_network\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# LSTM\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAA + AR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 'level', 'trend', 'acceleration', 'ETS'\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzB\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1E-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# initial mu for baseline hidden states\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSzB\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1E-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1E-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLA_var_stationary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSigma_AR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# var\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphi_AA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphi_AA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSigma_AR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSigma_AR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSigma_AA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSigma_AA\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# hybrid = LSTM_SSM(\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#     neural_network = net,           # LSTM\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#     baseline = 'AA + plain_AR', # 'level', 'trend', 'acceleration', 'ETS'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------------#\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     82\u001b[0m mses \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: LSTM_SSM.__init__() got an unexpected keyword argument 'Sigma_AA'"
     ]
    }
   ],
   "source": [
    "num_epochs: int = 50\n",
    "batch_size: int = 1\n",
    "sigma_v: float = 1\n",
    "\n",
    "\"\"\"Run training for time-series forecasting model\"\"\"\n",
    "# Dataset\n",
    "output_col = [0]\n",
    "num_features = 2\n",
    "input_seq_len = 26\n",
    "output_seq_len = 1\n",
    "seq_stride = 1\n",
    "\n",
    "train_dtl = TimeSeriesDataloader(\n",
    "    x_file=\"data/HQ/LGA007PIAP-E010_Y_train.csv\",\n",
    "    date_time_file=\"data/HQ/LGA007PIAP-E010_Y_train_datetime.csv\",\n",
    "    output_col=output_col,\n",
    "    input_seq_len=input_seq_len,\n",
    "    output_seq_len=output_seq_len,\n",
    "    num_features=num_features,\n",
    "    stride=seq_stride,\n",
    "    time_covariates = ['week_of_year'],  # 'hour_of_day','day_of_week', 'week_of_year', 'month_of_year','quarter_of_year'\n",
    ")\n",
    "test_dtl = TimeSeriesDataloader(\n",
    "    x_file=\"data/HQ/LGA007PIAP-E010_Y_val.csv\",\n",
    "    date_time_file=\"data/HQ/LGA007PIAP-E010_Y_val_datetime.csv\",\n",
    "    output_col=output_col,\n",
    "    input_seq_len=input_seq_len,\n",
    "    output_seq_len=output_seq_len,\n",
    "    num_features=num_features,\n",
    "    stride=seq_stride,\n",
    "    x_mean=train_dtl.x_mean,\n",
    "    x_std=train_dtl.x_std,\n",
    "    time_covariates = ['week_of_year'],  # 'hour_of_day','day_of_week', 'week_of_year'\n",
    ")\n",
    "\n",
    "# Network\n",
    "net = Sequential(\n",
    "    LSTM(num_features, 30, input_seq_len),\n",
    "    LSTM(30, 30, input_seq_len),\n",
    "    Linear(30 * input_seq_len, 1),\n",
    ")\n",
    "net.set_threads(8)\n",
    "# #net.to_device(\"cuda\")\n",
    "\n",
    "# # State-space models: for baseline hidden states\n",
    "phi_AA = 0.999\n",
    "Sigma_AR = 0.11453**2\n",
    "Sigma_AA = Sigma_AR*1e-17\n",
    "LA_var_stationary = Sigma_AA/(1-phi_AA**2)\n",
    "# Autoregressive acceleration + online AR\n",
    "hybrid = LSTM_SSM(\n",
    "    neural_network = net,           # LSTM\n",
    "    baseline = 'AA + AR', # 'level', 'trend', 'acceleration', 'ETS'\n",
    "    zB  = np.array([0.1, 1E-4, 0, 0.5, 0.02]),    # initial mu for baseline hidden states\n",
    "    SzB = np.array([1E-5, 1E-8, LA_var_stationary, 0.25, Sigma_AR]),    # var\n",
    "    phi_AA = phi_AA,\n",
    "    Sigma_AR = Sigma_AR,\n",
    "    Sigma_AA = Sigma_AA\n",
    ")\n",
    "# hybrid = LSTM_SSM(\n",
    "#     neural_network = net,           # LSTM\n",
    "#     baseline = 'AA + plain_AR', # 'level', 'trend', 'acceleration', 'ETS'\n",
    "#     zB  = np.array([0.1, 1E-18, 0, 0.02]),    # initial mu for baseline hidden states\n",
    "#     SzB = np.array([1E-5, 1E-5, LA_var_stationary, 1E-5])    # var\n",
    "# )\n",
    "# # Online AR\n",
    "# hybrid = LSTM_SSM(\n",
    "#     neural_network = net,           # LSTM\n",
    "#     baseline = 'trend + AR', # 'level', 'trend', 'acceleration', 'ETS'\n",
    "#     zB  = np.array([0.1, 1E-4, 0.5, 0.02]),      # initial mu for baseline hidden states\n",
    "#     SzB = np.array([1E-5, 1E-8, 0.25, Sigma_AR])    # var\n",
    "# )\n",
    "# hybrid = LSTM_SSM(\n",
    "#     neural_network = net,           # LSTM\n",
    "#     baseline = 'trend + plain_AR', # 'level', 'trend', 'acceleration', 'ETS'\n",
    "#     zB  = np.array([0.1, 1E-4, 0.02]),    # initial mu for baseline hidden states\n",
    "#     SzB = np.array([1E-5, 1E-5, 0.5])    # var\n",
    "# )\n",
    "\n",
    "# -------------------------------------------------------------------------#\n",
    "# Training\n",
    "mses = []\n",
    "\n",
    "pbar = tqdm(range(num_epochs), desc=\"Training Progress\")\n",
    "for epoch in pbar:\n",
    "    batch_iter = train_dtl.create_data_loader(batch_size, shuffle=False)\n",
    "\n",
    "    # Decaying observation's variance\n",
    "    sigma_v = exponential_scheduler(\n",
    "        curr_v=1E-12, min_v=1E-12, decaying_factor=1, curr_iter=epoch\n",
    "    )\n",
    "    var_y = np.full((batch_size * len(output_col),), sigma_v**2, dtype=np.float32)\n",
    "\n",
    "    # Initialize list to save\n",
    "    hybrid.init_ssm_hs()\n",
    "    mu_preds_lstm = []\n",
    "    var_preds_lstm = []\n",
    "    mu_preds_unnorm = []\n",
    "    obs_unnorm = []\n",
    "    mu_phiar = []\n",
    "    var_phiar = []\n",
    "    mu_aa = []\n",
    "    var_aa = []\n",
    "\n",
    "    for x, y in batch_iter:\n",
    "        mu_x, var_x = process_input_ssm(\n",
    "            mu_x = x, mu_preds_lstm = mu_preds_lstm, var_preds_lstm = var_preds_lstm,\n",
    "            input_seq_len = input_seq_len, num_features = num_features,\n",
    "            )\n",
    "\n",
    "        # Feed forward\n",
    "        y_pred, _, z_pred, Sz_pred, m_pred, v_pred = hybrid(mu_x, var_x)\n",
    "        # Backward\n",
    "        hybrid.backward(mu_obs = y, var_obs = var_y)\n",
    "\n",
    "        # Training metric\n",
    "        pred = normalizer.unstandardize(\n",
    "            y_pred.flatten(), train_dtl.x_mean[output_col], train_dtl.x_std[output_col]\n",
    "        )\n",
    "        obs = normalizer.unstandardize(\n",
    "            y, train_dtl.x_mean[output_col], train_dtl.x_std[output_col]\n",
    "        )\n",
    "        mse = metric.mse(pred, obs)\n",
    "        mses.append(mse)\n",
    "        mu_preds_lstm.extend(m_pred)\n",
    "        var_preds_lstm.extend(v_pred)\n",
    "        obs_unnorm.extend(y)\n",
    "        mu_preds_unnorm.extend(y_pred)\n",
    "        mu_phiar.append(z_pred[-3].item())\n",
    "        var_phiar.append(Sz_pred[-3][-3])\n",
    "        mu_aa.append(z_pred[2].item())\n",
    "        var_aa.append(Sz_pred[2][2])\n",
    "\n",
    "    # Smoother\n",
    "    hybrid.smoother()\n",
    "\n",
    "    mu_smoothed = np.array(hybrid.mu_smoothed)\n",
    "    cov_smoothed = np.array(hybrid.cov_smoothed)\n",
    "\n",
    "    # Figures for each epoch\n",
    "    plt.switch_backend('Agg')\n",
    "    plt.figure()\n",
    "    plt.plot(obs_unnorm, color='r',label=r\"obs.\")\n",
    "    plt.plot(mu_smoothed[:,0,:],color='k',label=r\"level\")\n",
    "    plt.fill_between(np.arange(len(mu_smoothed[:,0,:])), np.array(mu_smoothed[:,0,:]).flatten() - np.sqrt(cov_smoothed[:, 0, 0]), np.array(mu_smoothed[:,0,:]).flatten() + np.sqrt(cov_smoothed[:, 0, 0]), color='k', alpha=0.3, label='_nolegend_')\n",
    "    plt.plot(mu_smoothed[:,-2,:],color='g',label=r\"AR\")\n",
    "    plt.fill_between(np.arange(len(mu_smoothed[:,-2,:])), np.array(mu_smoothed[:,-2,:]).flatten() - np.sqrt(cov_smoothed[:, -2, -2]), np.array(mu_smoothed[:,-2,:]).flatten() + np.sqrt(cov_smoothed[:, -2, -2]), color='g', alpha=0.3, label='_nolegend_')\n",
    "    plt.plot(mu_preds_unnorm,color='b',label=r\"pred.\")\n",
    "    plt.plot(mu_smoothed[:,-1,:],color='orange',label=r\"LSTM\")\n",
    "    plt.fill_between(np.arange(len(mu_smoothed[:,-1,:])), np.array(mu_smoothed[:,-1,:]).flatten() - np.sqrt(cov_smoothed[:, -1, -1]), np.array(mu_smoothed[:,-1,:]).flatten() + np.sqrt(cov_smoothed[:, -1, -1]), color='orange', alpha=0.3, label='_nolegend_')\n",
    "    plt.legend(ncol = 3, loc='upper left')\n",
    "    filename = f'saved_results/hq_AA/hybrid_epoch_#{epoch}.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "    # figure for AR\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(mu_phiar)),mu_phiar,color='b',label=r\"AR\")\n",
    "    plt.fill_between(np.arange(len(mu_phiar)), np.array(mu_phiar) - np.sqrt(var_phiar), np.array(mu_phiar) + np.sqrt(var_phiar), color='blue', alpha=0.3, label='±1 SD')\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    filename = f'saved_results/hq_AA/phi_AR_epoch_#{epoch}.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "    # figure for AA\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(mu_aa)),mu_aa,color='b',label=r\"AR\")\n",
    "    plt.fill_between(np.arange(len(mu_aa)), np.array(mu_aa) - np.sqrt(var_aa), np.array(mu_aa) + np.sqrt(var_aa), color='blue', alpha=0.3, label='±1 SD')\n",
    "    filename = f'saved_results/hq_AA/AA_epoch_#{epoch}.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "    # Progress bar\n",
    "    pbar.set_description(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs}| mse: {np.nanmean(mses):>7.2f}\",\n",
    "        refresh=True,\n",
    "    )\n",
    "\n",
    "# print the value of AR\n",
    "print(f\"phi_AR: {mu_phiar[-1]}\")\n",
    "\n",
    "# -------------------------------------------------------------------------#\n",
    "# Testing\n",
    "test_batch_iter = test_dtl.create_data_loader(batch_size, shuffle=False)\n",
    "\n",
    "# Initialize list to save\n",
    "mu_preds = []\n",
    "var_preds = []\n",
    "y_test = []\n",
    "obs_test_unnorm = []\n",
    "#\n",
    "\n",
    "for x, y in test_batch_iter:\n",
    "    mu_x, var_x = process_input_ssm(\n",
    "        mu_x = x, mu_preds_lstm = mu_preds_lstm, var_preds_lstm = var_preds_lstm,\n",
    "        input_seq_len = input_seq_len,num_features = num_features,\n",
    "    )\n",
    "    # Feed forward\n",
    "    y_pred, Sy_red, _, _, m_pred, v_pred = hybrid(mu_x, var_x)\n",
    "\n",
    "    mu_preds.extend(y_pred)\n",
    "    var_preds.extend(Sy_red + sigma_v**2)\n",
    "    y_test.extend(y)\n",
    "    mu_preds_lstm.extend(m_pred)\n",
    "    var_preds_lstm.extend(v_pred)\n",
    "\n",
    "mu_preds = np.array(mu_preds)\n",
    "std_preds = np.array(var_preds) ** 0.5\n",
    "y_test = np.array(y_test)\n",
    "obs_test_unnorm = y_test\n",
    "mu_preds_unnorm_test = mu_preds\n",
    "std_preds_unnorm_test = std_preds\n",
    "\n",
    "mu_preds = normalizer.unstandardize(\n",
    "    mu_preds, train_dtl.x_mean[output_col], train_dtl.x_std[output_col]\n",
    ")\n",
    "std_preds = normalizer.unstandardize_std(std_preds, train_dtl.x_std[output_col])\n",
    "\n",
    "y_test = normalizer.unstandardize(\n",
    "    y_test, train_dtl.x_mean[output_col], train_dtl.x_std[output_col]\n",
    ")\n",
    "\n",
    "# Compute log-likelihood\n",
    "mse = metric.mse(mu_preds, y_test)\n",
    "log_lik = metric.log_likelihood(\n",
    "    prediction=mu_preds, observation=y_test, std=std_preds\n",
    ")\n",
    "\n",
    "#\n",
    "obs = np.concatenate((obs_unnorm,obs_test_unnorm), axis=0)\n",
    "idx_train = range(0,len(obs_unnorm))\n",
    "idx_test = range(len(obs_unnorm),len(obs))\n",
    "idx = np.concatenate((idx_train,idx_test),axis=0)\n",
    "mu_preds_unnorm_test = mu_preds_unnorm_test.flatten()\n",
    "std_preds_unnorm_test = std_preds_unnorm_test.flatten()\n",
    "\n",
    "# figure for final test predictions\n",
    "plt.figure()\n",
    "plt.plot(idx,obs, color='r',label=r\"data\")\n",
    "plt.plot(idx_test, mu_preds_unnorm_test, color='b',label=r\"test prediction\")\n",
    "plt.fill_between(idx_test, mu_preds_unnorm_test - std_preds_unnorm_test, mu_preds_unnorm_test + std_preds_unnorm_test, color='blue', alpha=0.3, label='±1 SD')\n",
    "plt.plot(idx_train,mu_smoothed[:,0,:],color='k',label=r\"level\")\n",
    "plt.plot(idx_train, mu_preds_unnorm,color='g', label=r\"train prediction\")\n",
    "filename = f'saved_results/hq_AA/test_prediction14.png'\n",
    "plt.savefig(filename)\n",
    "plt.close()  # Close the plot to free up memory\n",
    "\n",
    "print(\"#############\")\n",
    "print(f\"MSE           : {mse: 0.2f}\")\n",
    "print(f\"Log-likelihood: {log_lik: 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.net.save(filename = './saved_param/HQ_hybrid_LSTM/lstm_hq_hybrid_onlydisp14.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytagi_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
